#!/usr/bin/env python

################################################################################
#  This script needs a ton of refactoring... it's pretty much brute force now  #
################################################################################
try:
    from yaml import load, Loader, dumpCDumper as Dumper
except ImportError:
    from yaml import Loader, Dumper

#import sys
import os
import time
import shutil
from datetime import datetime
import subprocess
import argparse
from collections import OrderedDict

#for diffing models
from deepdiff import DeepDiff
from pprint import pprint

from helpers import *
from migrations import MigrationBuilder
from sbt import SbtBuilder
from db_access import security_info, DbAccessBuilder
from models import ModelBuilder
from encoders import EncoderBuilder
from api import ApiBuilder
from misc_builders import *
from default_models import *
from app import *



#read in a yaml file for models and do some  cleanup
def read_models(model_stream, casing):
    model_data = load(model_stream, Loader=Loader)
    #automatically add user tables if selected
    if 'users' in app_data['app']:
        model_data.append(DEFAULT_USER_MODEL)
        model_data.append(DEFAULT_SOCIAL_USER_MODEL)

    #make sure that all models have an id and timestamps
    for index in range(len(model_data)):
        model = model_data[index]
        Model(model, casing)
        cols = model["columns"]

        timestamps = True
        if 'timestamps' in model:
            timestamps = model['timestamps']

        if 'db_name' not in model:
            if casing == "snake_case":
                model_data[index]["db_name"] = underscore(model["name"])
            elif casing == "camel_case":
                model_data[index]["db_name"] = camelize(model["name"], False)
            else:
                model_data[index]["db_name"] = model["name"]

        else:
            model_data[index]["db_name"] = model["db_name"]

        if "id" not in cols:
            model_data[index]["columns"].insert(0, {
                "name": "id",
                "auto_increment" : True,
                "type" : "bigint",
                "primary_key" : True,
                "validations": ["positive"]
            })

        if 'created_at' not in cols and timestamps:
            model_data[index]["columns"].append({
                "name": "created_at",
                "type" : "timestamp",
                "default": "NOW()",
                "nullable": True
            })

        if 'updated_at' not in cols and timestamps:
            model_data[index]["columns"].append({
                "name": "updated_at",
                "type" : "timestamp",
                "default": "NOW()",
                "nullable": True
            })

        #handle implicit validations if there is a limit given
        #and also add any implicit formatters
        for i in range(len(model_data[index]["columns"])):
            col = model_data[index]["columns"][i]
            if not "validations" in col:
                col["validations"] = []

            if 'limit' in col:
                col["validations"].append({"max_length": col["limit"]})

            if not 'formatters' in col:
                col['formatters'] = []

            #some implicit formatters
            if col['type'] in ('phone', 'postal_code', 'social_security', 'list'):
                #add the formatters
                col['formatters'].extend(get_formatters(col['type']))

            model_data[index]["columns"][i] = col
    return model_data


if __name__ == "__main__":

    parser = argparse.ArgumentParser("generate")
    parser.add_argument("-p", "--project-file", help="location of project.yml", required=True)
    parser.add_argument("-m", "--model-file", help="location of model.yml", required=True)
    parser.add_argument("-d", "--source-directory", help="location generated sources", default=".")
    args = parser.parse_args()

    model_stream_file = os.path.abspath(args.model_file)
    model_stream = open(model_stream_file)
    app_stream = open(args.project_file)

    #make copies so we can do diffs on the models
    app_data = load(app_stream, Loader=Loader)

    app_data["app"]["source_directory"] = os.path.abspath(args.source_directory)


    gen_options = app_data.get('generator', {})
    casing = "snake_case"
    if "casing" in app_data["db"]:
        casing = app_data["db"]["casing"]

    model_data = read_models(model_stream, casing)
    try:
        old_model_stream = open(
            os.path.abspath(args.model_file)\
                                .replace(".yml", "-backup.yml")
        )
        old_model_data = read_models(old_model_stream, casing)
    except Exception, e:
        old_model_data = {}




    def get(data, key):
        for k in data:
            if k['db_name'] == key:
                return k
        return {}

    def to_list(dct):
        lst = []
        for k,v in dct.items():
            lst.append(v)
        return lst

    #models in old that are not in new... eg, drop
    migrations = OrderedDict()
    for meta in [m for m in old_model_data if m.get('generate_migration', True)]:
        m = get(model_data, meta['db_name'])
        if m == {}:
            migrations[meta['db_name']] = {"drop_table": meta['db_name'] }

    for meta in [m for m in model_data if m.get('generate_migration', True)]:
        old_meta = get(old_model_data, meta['db_name'])

        #if it exsists in new but not in old
        if old_meta == {}:
            diff = {'create_table': meta}
        else:
            diff = DeepDiff(old_meta, meta,  ignore_order = True)

        if diff != {}:
            migrations[meta['db_name']] = {
                "create_table": diff.get("create_table", {}),
                "added": to_list(diff.get('iterable_item_added', {})),
                "removed": to_list(diff.get('iterable_item_removed', {})),
                "altered": []
        }

        #cleanup up cases where a column is in both added and removed
        #this indicates an 'alter'
        if meta['db_name'] in migrations:
            added = migrations[meta['db_name']]['added']
            removed = migrations[meta['db_name']]['removed']

            for c in added:
                for c2 in removed:
                    if c['name'] == c2['name']:
                        migrations[meta['db_name']]['altered'].append(c)
                        migrations[meta['db_name']]['added'] =  [x for x in migrations[meta['db_name']]['added']
                                                                 if x['name'] !=c['name']]

                        migrations[meta['db_name']]['removed'] =  [x for x in migrations[meta['db_name']]['removed']
                                                                   if x['name'] !=c['name']]

    pprint(migrations, indent=2)

    app_data['migrations'] = migrations

    app = App(app_data, model_data, casing)

    scala_dirs = [app.base_path]

    #for d in ('api', 'encoders', 'models', 'migrations'):

    if key_with_default(gen_options, "sbt", True):
        print("Generating project build files...")
        sbt_builder = SbtBuilder(app)

    if key_with_default(gen_options, "models", True):
        print("Generating models...")
        model_builder = ModelBuilder(app, )
        access_builder =  DbAccessBuilder(app)

    if key_with_default(gen_options, "migrations", True):
        print("Generating migrations...")
        migration_builder = MigrationBuilder(app)
        #copy the new models.yml to models-backup.yml
        #after successful migration generation
        shutil.copyfile(model_stream_file, model_stream_file.replace(".yml", "-backup.yml"))

    if key_with_default(gen_options, "encoders", True):
        print("Generating JSON encoders/decoders...")
        encoder_builder = EncoderBuilder(app)

    if key_with_default(gen_options, "api", True):
        print("Generating API Endpoints...")
        api_builder = ApiBuilder(app)
        build_boot(app)
        build_api_service(app)


    print("Generating logging configuration...")
    build_logback(app)
    print("Generating app launch configuration..")
    build_app_ini(app)
    print("Copying external tools...")
    copy_tools(app)

    if key_with_default(gen_options, "format_source", True):
      print("Formatting Scala sources...")
      format_scala(scala_dirs)

    message = """Your project is now aourailable in %s. To run, simply
    cd into %s and then type "sbt run". Your API will be available at http://localhost:%s/api/[model_name]""" % (app.source_directory, app.source_directory, app.port)

    print
    print(message)
